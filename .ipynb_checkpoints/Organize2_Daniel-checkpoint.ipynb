{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries needed \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "# libraries we might not need\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the following code\n",
    "to use the whole document you only need one file specified by filepath for the time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16) <- size of dataframe \n",
      "\n",
      "CPU times: user 2.2 s, sys: 73.3 ms, total: 2.27 s\n",
      "Wall time: 2.27 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>content</th>\n",
       "      <th>authors</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>url</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tags</th>\n",
       "      <th>type</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48770</th>\n",
       "      <td>3660</td>\n",
       "      <td>World View: Both Greece and European Leaders S...</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>this morning s key headlines from generational...</td>\n",
       "      <td>John J. Xenakis</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>http://www.breitbart.com/national-security/201...</td>\n",
       "      <td>['Alexis Tsipras', 'Angela Merkel', 'Britain',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>breitbart.com</td>\n",
       "      <td>World View: Both Greece and European Leaders S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tunisia, Generational Dynamics, Britain, Alexi...</td>\n",
       "      <td>political</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96003</th>\n",
       "      <td>7278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>daily app fix april &lt;number&gt; th &lt;number&gt; risk ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>http://beforeitsnews.com/science-and-technolog...</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Daily App Fix April 20th 2013 – RISK, Connect ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16182</th>\n",
       "      <td>4317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>consciousness and unified physics are the keys...</td>\n",
       "      <td>Waking Times</td>\n",
       "      <td>2018-01-25 16:17:44.789555</td>\n",
       "      <td>http://beforeitsnews.com/alternative/2016/07/c...</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Consciousness and Unified Physics are the Keys...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89922</th>\n",
       "      <td>1932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>do something , anything headline : bitcoin blo...</td>\n",
       "      <td>Humble Student Of The Markets</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>http://beforeitsnews.com/financial-markets/201...</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beforeitsnews.com</td>\n",
       "      <td>Do something, anything!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fake</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106668</th>\n",
       "      <td>5321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>from conservapedia transfer pricing is the set...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>http://www.conservapedia.com/Transfer_Pricing</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>conservapedia.com</td>\n",
       "      <td>Transfer Pricing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bias</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                   meta_description  \\\n",
       "id                                                                      \n",
       "48770         3660  World View: Both Greece and European Leaders S...   \n",
       "96003         7278                                                NaN   \n",
       "16182         4317                                                NaN   \n",
       "89922         1932                                                NaN   \n",
       "106668        5321                                                NaN   \n",
       "\n",
       "                        updated_at  \\\n",
       "id                                   \n",
       "48770   2018-02-02 01:19:41.756664   \n",
       "96003   2018-02-02 01:19:41.756664   \n",
       "16182   2018-02-02 01:19:41.756664   \n",
       "89922   2018-02-02 01:19:41.756664   \n",
       "106668  2018-02-02 01:19:41.756664   \n",
       "\n",
       "                                                  content  \\\n",
       "id                                                          \n",
       "48770   this morning s key headlines from generational...   \n",
       "96003   daily app fix april <number> th <number> risk ...   \n",
       "16182   consciousness and unified physics are the keys...   \n",
       "89922   do something , anything headline : bitcoin blo...   \n",
       "106668  from conservapedia transfer pricing is the set...   \n",
       "\n",
       "                              authors                  scraped_at  \\\n",
       "id                                                                  \n",
       "48770                 John J. Xenakis  2018-01-25 20:13:50.426130   \n",
       "96003                             NaN  2018-01-25 20:13:50.426130   \n",
       "16182                    Waking Times  2018-01-25 16:17:44.789555   \n",
       "89922   Humble Student Of The Markets  2018-01-25 20:13:50.426130   \n",
       "106668                            NaN  2018-01-25 20:13:50.426130   \n",
       "\n",
       "                                                      url  \\\n",
       "id                                                          \n",
       "48770   http://www.breitbart.com/national-security/201...   \n",
       "96003   http://beforeitsnews.com/science-and-technolog...   \n",
       "16182   http://beforeitsnews.com/alternative/2016/07/c...   \n",
       "89922   http://beforeitsnews.com/financial-markets/201...   \n",
       "106668      http://www.conservapedia.com/Transfer_Pricing   \n",
       "\n",
       "                                            meta_keywords  summary  \\\n",
       "id                                                                   \n",
       "48770   ['Alexis Tsipras', 'Angela Merkel', 'Britain',...      NaN   \n",
       "96003                                                ['']      NaN   \n",
       "16182                                                ['']      NaN   \n",
       "89922                                                ['']      NaN   \n",
       "106668                                               ['']      NaN   \n",
       "\n",
       "                   domain                                              title  \\\n",
       "id                                                                             \n",
       "48770       breitbart.com  World View: Both Greece and European Leaders S...   \n",
       "96003   beforeitsnews.com  Daily App Fix April 20th 2013 – RISK, Connect ...   \n",
       "16182   beforeitsnews.com  Consciousness and Unified Physics are the Keys...   \n",
       "89922   beforeitsnews.com                            Do something, anything!   \n",
       "106668  conservapedia.com                                   Transfer Pricing   \n",
       "\n",
       "        keywords                                               tags  \\\n",
       "id                                                                    \n",
       "48770        NaN  Tunisia, Generational Dynamics, Britain, Alexi...   \n",
       "96003        NaN                                                NaN   \n",
       "16182        NaN                                                NaN   \n",
       "89922        NaN                                                NaN   \n",
       "106668       NaN                                                NaN   \n",
       "\n",
       "             type                 inserted_at  source  \n",
       "id                                                     \n",
       "48770   political  2018-02-02 01:19:41.756632     NaN  \n",
       "96003        fake  2018-02-02 01:19:41.756632     NaN  \n",
       "16182        fake  2018-02-02 01:19:41.756632     NaN  \n",
       "89922        fake  2018-02-02 01:19:41.756632     NaN  \n",
       "106668       bias  2018-02-02 01:19:41.756632     NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# imports a random sample of size s from csv-file as a pandas dataframe\n",
    "# pandas using python 3.X uses utf-8 encoding\n",
    "\n",
    "# usage: specify file location, sample size and seed(used by random)\n",
    "filepath = '/home/daniel/Downloads/clean-100k.csv'\n",
    "#filepath = 'news_sample.csv' # <- overwrite for setup\n",
    "s = 1000                      # desired sample size(seems to have slack ie. not exact)\n",
    "seed = 1                     # seed used by Pseudorandom number generator\n",
    "\n",
    "# init dataframe with specified values\n",
    "df = pd.read_csv(filepath).sample(n=s, random_state=seed)\n",
    "\n",
    "# set dataframe index to article id - use df.to_csv('tmp.csv', index=True, header=True) as index=True writes index to csv with index_name\n",
    "df.set_index('id', inplace=True)\n",
    "\n",
    "# visual output\n",
    "print(df.shape, '<- size of dataframe \\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data-tables: [name]-uniq / relational-tables: [name]_in\n",
    "creating csv-files for database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify where to save all csv-files\n",
    "path = 'database_csv_in2/'\n",
    "\n",
    "# create temporary dataframe and use article id as index \n",
    "out_df = pd.DataFrame({'id':df.index})\n",
    "out_df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### types_uniq - data-table ###\n",
    "type_array = df.type.unique() # get array of unique types\n",
    "type_df = pd.DataFrame({'id': np.arange(type_array.size), 'name':type_array})\n",
    "\n",
    "# write file and free memory\n",
    "type_df.to_csv(path + 'type_clean.csv', index=False, header=True)\n",
    "#del type_array\n",
    "#del type_df # tmp delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tags_uniq - data-table ###\n",
    "\n",
    "# creates list of list but formaly it is a pd.series of lists\n",
    "tags_series_of_lists = df.tags.dropna().str.split(', ') # -> ', ' not ','\n",
    "\n",
    "if not 'tags' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'tags', value = tags_series_of_lists)\n",
    "\n",
    "# flattern tags_series_of_lists to a set(ie. unique values only)\n",
    "tags_list = list(set([item for sublist in tags_series_of_lists for item in sublist]))\n",
    "\n",
    "# create dataframe\n",
    "tags_df = pd.DataFrame({'id': np.arange(len(tags_list)), 'name':tags_list})\n",
    "\n",
    "# write file and free memory\n",
    "tags_df.to_csv(path + 'tags_clean.csv', index=False, header=True)\n",
    "del tags_series_of_lists\n",
    "del tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tags_in - relational-table ###\n",
    "\n",
    "# get all pairs of article_id and tags in a article (for all articles)\n",
    "articles_id_tags_name_pairs_df = out_df.tags.dropna().explode()\n",
    "\n",
    "# split tags_name and articles_id\n",
    "articles_id_array = articles_id_tags_name_pairs_df.index.to_numpy()\n",
    "tags_name_array = articles_id_tags_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap tags with tags_id]\n",
    "tags_name_as_key_df = tags_df.set_index('name')\n",
    "tags_dict = tags_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace tags with tag id\n",
    "tags_id = np.array([tags_dict[key] for key in tags_name_array])\n",
    "\n",
    "# create dataframe\n",
    "tags_in_df = pd.DataFrame(data=articles_id_array, index=tags_id, columns=['article_id'])\n",
    "tags_in_df.index.name='tags_id'\n",
    "\n",
    "# write file and free memory\n",
    "tags_in_df.to_csv(path + 'tags_in.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### authors-uniq - data-table ###\n",
    "\n",
    "# creates list of list but formaly it is a pd.series of lists\n",
    "authors_series_of_lists = df.authors.dropna().str.split(',') # -> ',' not ', '\n",
    "\n",
    "if not 'authors' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'authors', value = authors_series_of_lists)\n",
    "\n",
    "# flattern authors_series_of_lists to a set(ie. unique values only)\n",
    "authors_list = list(set([item for sublist in authors_series_of_lists for item in sublist]))\n",
    "\n",
    "# create dataframe\n",
    "authors_df = pd.DataFrame({'id': np.arange(len(authors_list)), 'name':authors_list})\n",
    "\n",
    "# write file and free memory\n",
    "authors_df.to_csv(path + 'authors_clean.csv', index=False, header=True)\n",
    "#del authors_series_of_lists\n",
    "#del authors_list\n",
    "#del authors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### authors_in - relational-table ###\n",
    "\n",
    "# get all pairs of article_id and authors in a article (for all articles)\n",
    "articles_id_authors_name_pairs_df = out_df.authors.dropna().explode()\n",
    "\n",
    "# split authors_name and articles_id\n",
    "articles_id_array = articles_id_authors_name_pairs_df.index.to_numpy()\n",
    "authors_name_array = articles_id_authors_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap authors with authors_id]\n",
    "authors_name_as_key_df = authors_df.set_index('name')\n",
    "authors_dict = authors_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace authors with tag id\n",
    "authors_id = np.array([authors_dict[key] for key in authors_name_array])\n",
    "\n",
    "# create dataframe\n",
    "authors_in_df = pd.DataFrame(data=articles_id_array, index=authors_id, columns=['article_id'])\n",
    "authors_in_df.index.name='authors_id'\n",
    "\n",
    "# write file and free memory\n",
    "authors_in_df.to_csv(path + 'authors_in.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### domains-uniq - data-table ###\n",
    "domain_array = df.domain.unique() # get array of unique domains\n",
    "domain_df = pd.DataFrame({'id': np.arange(domain_array.size), 'name':domain_array})\n",
    "\n",
    "# write file and free memory\n",
    "domain_df.to_csv(path + 'domain_name_clean.csv', index=False, header=True)\n",
    "#del domain_array\n",
    "#del domain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### meta_keywords_uniq - data-table ###\n",
    "\n",
    "# use regex to remove string-padding\n",
    "regex = r\" *['\\\"\\[\\]]+\"\n",
    "meta_keywords_series = df.meta_keywords.replace(to_replace=regex, value='', regex=True).str.split(',')\n",
    "#meta_keywords_series = meta_keywords_series.replace(r'', np.NaN)\n",
    "\n",
    "if not 'meta_keywords' in out_df: ### tmp need another method ###\n",
    "    out_df.insert(0,column = 'meta_keywords', value = meta_keywords_series)\n",
    "\n",
    "# create array of unique\n",
    "meta_keywords_set = meta_keywords_series.explode().unique()\n",
    "\n",
    "# create dataframe\n",
    "meta_keywords_df = pd.DataFrame({'id': np.arange(len(meta_keywords_set)), 'name':meta_keywords_set})\n",
    "\n",
    "# write file and free memory\n",
    "meta_keywords_df.to_csv(path + 'meta_keywords_clean.csv', index=False, header=True)\n",
    "#del meta_keywords_series\n",
    "#del meta_keywords_set\n",
    "#del meta_keywords_list\n",
    "#del meta_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### meta_keywords_in - relational-table ###\n",
    "\n",
    "# get all pairs of article_id and meta_keywords in a article (for all articles)\n",
    "articles_id_meta_keywords_name_pairs_df = out_df.meta_keywords.dropna().explode()\n",
    "\n",
    "# split meta_keywords_name and articles_id\n",
    "articles_id_array = articles_id_meta_keywords_name_pairs_df.index.to_numpy()\n",
    "meta_keywords_name_array = articles_id_meta_keywords_name_pairs_df.to_numpy()\n",
    "\n",
    "# create dict with tag_name as key - [swap meta_keywords with meta_keywords_id]\n",
    "meta_keywords_name_as_key_df = meta_keywords_df.set_index('name')\n",
    "meta_keywords_dict = meta_keywords_name_as_key_df['id'].to_dict()\n",
    "\n",
    "# replace meta_keywords with tag id\n",
    "meta_keywords_id = np.array([meta_keywords_dict[key] for key in meta_keywords_name_array])\n",
    "\n",
    "# create dataframe\n",
    "meta_keywords_in_df = pd.DataFrame(data=articles_id_array, index=meta_keywords_id, columns=['article_id'])\n",
    "meta_keywords_in_df.index.name='meta_keywords_id'\n",
    "\n",
    "# write file and free memory\n",
    "meta_keywords_in_df.to_csv(path + 'meta_keywords_in.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### depricated - might be useful later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row-function used for extracting article and uniq_[name] id\n",
    "def article_and_uniq_name_id(row, name_df):\n",
    "    # test for overlap(isin) between article_row and uniq_[name] and create np_array\n",
    "    tmp_df = name_df[name_df['name'].isin(row[0])] # MAYBE FASTER -> ONLY RETURN ONE COLUMN\n",
    "    tmp_np_array = tmp_df.values\n",
    "    \n",
    "    # create np_array with row_id for each uniq_[name]\n",
    "    row_id = np.full((np.size(tmp_np_array,0), 1), row.name)\n",
    "    \n",
    "    # combine\n",
    "    tmp_np_array = np.append(tmp_np_array, row_id, axis=1)\n",
    "\n",
    "    #print('>', tmp_df)\n",
    "    # change numer of columns to return [col_1, col2, ...]\n",
    "    return tmp_np_array[:, [0, -1]] # MAYBE NOT NEEDED IF CHAGED TO ONE ROW IE. FASTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relational tags_in\n",
    "\n",
    "#tags_series_of_lists = out_df[['tags']].dropna().apply(article_and_uniq_name_id, axis='columns', args=(tags_df, )) \n",
    "tags_series_of_lists = out_df[['tags']].dropna().apply(article_and_uniq_name_id, axis='columns', args=(tags_df, )) \n",
    "\n",
    "# concat series into one np_array\n",
    "tags_in_ndarray = [element for list_ in tags_series_of_lists for element in list_]\n",
    "\n",
    "# create dataframe\n",
    "tags_in_df = pd.DataFrame(data = tags_in_ndarray, columns = ['tag_id', 'article_id'])\n",
    "\n",
    "# write file and free memory\n",
    "tags_in_df.to_csv(path + 'tags_in.csv', index=True, index_label='id', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relational authors_in\n",
    "\n",
    "# series of np_arrays - \n",
    "authors_series_of_lists = out_df[['authors']].dropna().apply(article_and_uniq_name_id, axis='columns', args=(authors_df, )) \n",
    "\n",
    "# concat series into one np_array\n",
    "authors_in_ndarray = [element for list_ in authors_series_of_lists for element in list_]\n",
    "\n",
    "# create dataframe\n",
    "authors_in_df = pd.DataFrame(data = authors_in_ndarray, columns = ['tag_id', 'article_id'])\n",
    "\n",
    "# write file and free memory\n",
    "authors_in_df.to_csv(path + 'authors_in.csv', index=True, index_label='id', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75, 48770],\n",
       "       [652, 16182],\n",
       "       [48, 89922],\n",
       "       ...,\n",
       "       [72, 11270],\n",
       "       [267, 11270],\n",
       "       [621, 11270]], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_in_ndarray = np.array([element for list_ in authors_series_of_lists for element in list_])\n",
    "authors_in_ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.006261 s\n",
       "File: <ipython-input-53-120198c43a9e>\n",
       "Function: myFunc at line 2\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     2                                           def myFunc():\n",
       "     3         1       1908.0   1908.0     30.5      authors_in_ndarray = authors_series_of_lists.explode()\n",
       "     4         1         14.0     14.0      0.2      authors_series_of_lists.to_numpy()\n",
       "     5         1       4339.0   4339.0     69.3      authors_series_of_lists.dropna()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f myFunc myFunc()\n",
    "def myFunc():\n",
    "    authors_in_ndarray = authors_series_of_lists.explode()\n",
    "    authors_in_ndarray.to_numpy()\n",
    "    authors_in_ndarray.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('DS': conda)",
   "language": "python",
   "name": "python37764bitdsconda217f41063fe24cf89ccdf8aa73f962cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
